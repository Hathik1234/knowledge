from databricks import sql
import argparse
import yaml
import logging
import os
import sys
from pathlib import Path
from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker
import subprocess
import cx_Oracle
import json


def load_and_validate_yaml(yaml_path):

    """ Load Configuration data from YAML file
        Returns: Dictionary - if success """
    try:
        if not os.path.isfile(yaml_path):
            raise FileNotFoundError(f"ERROR - The YAML file '{yaml_path}' does not exist.")

        with open(yaml_path, "r") as yaml_file:
            data = yaml.safe_load(yaml_file)

        if not data:
            raise ValueError("ERROR - The study specific YAML configuration file is empty.")
        return data
    except (yaml.YAMLError, ValueError, FileNotFoundError) as e:
       raise ValueError(f"ERROR - YAML validation failed - {e}")

def update_audit_log_table(session, status, msg, audit_log_sq_no):
    """
    Update the audit log table with the provided status and message.
    """
    try:
        logging.info("Updating Audit Log table with FAIL status and Error msg")
        audit_sql = text("""UPDATE BARDSCPI.SDTM_AUDIT_LOG SET STATUS_CD = :status, STATUS_MSG = :msg WHERE AUDIT_LOG_SEQ_NO = :seq_no""")
        session.execute(audit_sql, {
            "status": status,
            "msg": str(msg),
            "seq_no": int(audit_log_sq_no)
        })
        session.commit()
    except Exception as e:
        # roll back stmnt
        logging.error(f"Error while updating Audit Log Table with Fail Status: {e}")
        raise

def establish_databricks_connection(config, session, audit_log_sq_no, logfile_path, oracle_server_scp):

    """ Get the details from YAML to connect to Databricks
        Returns: Connection string """
    try:
        logging.info("Establishing connection to databricks")
        #Get databricks connectivity details from YAML
        server_hostname = config['databricks_conn']['server_hostname']
        https_path = config['databricks_conn']['https_path']
        token = config['databricks_conn']['access_token']
    
        # Connect to Databricks
        connection = sql.connect(
            server_hostname=server_hostname,
            http_path=https_path,
            access_token=token
         )

        return connection

    except Exception as e:
        logging.error(f"Error while connecting to databricks: {e}")
        zip_and_transfer(audit_log_sq_no, logfile_path, oracle_server_scp)
        # Updating audit_log table
        error_msg =  """<br>
        <strong>ExtractCDLSDTMDataException:</strong> System encountered an error while connecting to CDL Databricks server.<br>
        <strong>Error Cause:</strong> Connectivity error encountered.<br>
		<strong>Next Steps:</strong> Submit a CPI request to report the issue."""
        update_audit_log_table(session, 'FAIL', error_msg, audit_log_sq_no)
        raise

def get_oracle_db_session(config):

    """ Get the details from YAML to connect to Onprem oracle Database
        Returns: Connection string """
    
    try:
        logging.info("Establishing Oracle Session")
        #Get databricks connectivity details from YAML
        user_name = config['oracle_conn']['user_name']
        password  =  config['oracle_conn']['pwd']
        host = config['oracle_conn']['jdbc_host']
        port = config['oracle_conn']['jdbc_port']
        sid = config['oracle_conn']['jdbc_sid']

        # Setup and connect to Oracle DB
        connection_string = "oracle+cx_oracle://{}:{}@{}:{}/{}".format(user_name, password, host, port, sid)
        engine = create_engine(connection_string)

        Session = sessionmaker(bind=engine)
        session = Session()
        return session

    except Exception as e:
        logging.error(f"Exits Python- Error while connecting to Onprem Oracle DB: {e}")
        raise


def fetch_databricks_table_info(conn, catalog_name, schema_name, session, audit_log_sq_no, logfile_path, oracle_server_scp):

    """ Gets list of domain/tables for the study by connecting to Databricks
        Returns:  Domains/tables list"""
    
    try:
        logging.info("Inside fetch_databricks_table_info Method")
        query = f"SHOW TABLES IN `{catalog_name}`.`{schema_name}`";
        with conn.cursor() as cursor:
            cursor.execute(query)
            tables = cursor.fetchall()
        all_domains = [tableName for _, tableName, _ in tables]

        logging.info("Available Domains list")
        logging.info(all_domains)

        exclude_domains = fetch_exclude_domain_list(session, audit_log_sq_no, logfile_path, oracle_server_scp)

        logging.info("Exclude domains list")
        logging.info(exclude_domains)

        domains = [domain for domain in all_domains if domain not in exclude_domains]
        return domains

    except Exception as e:
        logging.error(f"Error while fetching domains from databricks: {e}")
        zip_and_transfer(audit_log_sq_no, logfile_path, oracle_server_scp)
        # Updating audit_log table
        error_msg =  """<br>
        <strong>ExtractCDLSDTMDataException:</strong> System encountered an error while listing the Domains from CDL Databricks study schema.<br>
        <strong>Error Cause:</strong> Connectivity error encountered.<br>
		<strong>Next Steps:</strong> Submit a CPI request to report the issue."""
        update_audit_log_table(session, 'FAIL', error_msg, audit_log_sq_no)
        raise


def validate_schema_existence(conn, catalog_name, schema_name, session, audit_log_sq_no, logfile_path, oracle_server_scp):

    """ Check if schema exits in catalog
        Returns:  True -  If schema is present
                  False - If schema not present """

    try:
        logging.info("Inside validate_schema_existence Method")
        query = f"SHOW SCHEMAS IN `{catalog_name}`";
        with conn.cursor() as cursor:
            cursor.execute(query)
            schemas = cursor.fetchall()

        schema_list = [row.databaseName for row in schemas]

        if schema_name in schema_list:
            return True
        else:
            return False

    except Exception as e:
        logging.error(f"Error while checking the schema presence in databricks: {e}")
        zip_and_transfer(audit_log_sq_no, logfile_path, oracle_server_scp)
        # Updating audit_log table
        error_msg = """<br>
        <strong>ExtractCDLSDTMDataException:</strong> Error while fetching the schema details from databricks Catalog.<br>
        <strong>Error Cause:</strong> Connectivity error encountered.<br>
		<strong>Next Steps:</strong> Submit a CPI request to report the issue."""
        update_audit_log_table(session, 'FAIL', error_msg, audit_log_sq_no)
        raise


def fetch_query_results(query, connection):
    """Fetch columns and data from a query result."""
    try:
        logging.info("Inside fetch_query_results")
        with connection.cursor() as cursor:
            cursor.execute(query)
            columns = [desc[0] for desc in cursor.description]
            data = cursor.fetchall()
            return columns, data

    except Exception as e:
        logging.error(f"Error while executing databricks query: {e}")
        raise


def fetch_exclude_domain_list(session, audit_log_sq_no, logfile_path, oracle_server_scp):
    """Fetch the exclude domain from CDL_DOMAIN_EXCEPTION table"""
    try:
        logging.info("Inside fetch_exclude_domain_list Method")
        fetch_query = text(f"select DOMAIN_NAME from BARDSCPI.CDL_DOMAIN_EXCEPTION where EXTRACTION_TYPE='SDTM' and DOMAIN_NAME is not null")
        result = session.execute(fetch_query).fetchall()
        if result:
            values = [item for row in result for item in row[0].split(',')]
            domains_ex_list = [domain for domain in values]
        else:
            domains_ex_list = []
        return domains_ex_list
    except Exception as e:
        logging.error(f"Error while fetching exclude domains from CDL_DOMAIN_EXCEPTION: {e}")
        zip_and_transfer(audit_log_sq_no, logfile_path, oracle_server_scp)
        error_msg =  """<br>
        <strong>ExtractCDLSDTMDataException:</strong> Error while fetching the exclude domain details from CPI database.<br>
        <strong>Error Cause:</strong> Connectivity error encountered.<br>
		<strong>Next Steps:</strong> Submit a CPI request to report the issue."""
        update_audit_log_table(session, 'FAIL', error_msg, audit_log_sq_no)
        raise
    

def start_background_task(config, domains, dataset_log_sq_no):
    """Run background processing independently"""

    try:
        logging.info("Inside start_background_task Method")
        config_str = json.dumps(config)
        dataset_log_sq_no_str = str(dataset_log_sq_no)

        cmd = ["nohup", "python3", "/opt/bardscpi/BARDSCPIDEV/bardscpi/python_sdtm/async_sas_ds_generation.py", config_str, domains, dataset_log_sq_no_str, "&" ]
        # Execute the command
        subprocess.Popen(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

    except Exception as e:
        logging.error(f"Error while running a subprocess: {e}")
        raise


def zip_and_transfer(audit_log_sq_no, logfile_path, oracle_server_scp):
    """Create a Zip file for the Log file and copy/scp to mail server"""
    try:
        zip_file_name = f"{audit_log_sq_no}.zip"
        zip_command = ['/bin/zip', '-j', zip_file_name, logfile_path]
        subprocess.run(zip_command, check=True)
        scp_command = ['/bin/scp', '-p', zip_file_name, f"{oracle_server_scp}:/opt/bardscpi/mailattachments"]
        subprocess.run(scp_command, check=True)

        if os.path.exists(zip_file_name):
            logging.info("Zip file created for SCP is deleted successfully")
            os.remove(zip_file_name)

        logging.info(f"Successfully zipped and transferred {zip_file_name}.")

    #except subprocess.CalledProcessError as e:
    #logging.error(f"An error occurred while executing a command: {e}")

    except Exception as e:
        error_msg =  """<br>
        <strong>ExtractCDLSDTMDataException:</strong> Error while creating a zip and transferring data to mail server.<br>
        <strong>Error Cause:</strong> Connectivity error encountered.<br>
		<strong>Next Steps:</strong> Submit a CPI request to report the issue."""
        update_audit_log_table(session, 'FAIL', error_msg, audit_log_sq_no)
        logging.error(f"An unexpected error occurred: {e}")



def main():

    """ Parse command line arguments and execute the SQL query based on the provided configuration file. """

    try:
        # Creating argument parser object to work with command line arguments
        parser = argparse.ArgumentParser(description="YAML file path")
        parser.add_argument("--yamlpath",  help="YAML file path", required=True)
        args = parser.parse_args()
        yaml_file_path = args.yamlpath

        if not yaml_file_path.endswith('.yaml'): 
           sys.exit(1)

        config = load_and_validate_yaml(yaml_file_path)


        #fetch details from config
        audit_log_sq_no =  config['audit_log']['seq_no']
        sas_output_path =  config['audit_log']['study_path']
        catalog_name = config['databricks_conn']['catalog_name']
        schema_name = config['audit_log']['study_schema']
        study_name = config['audit_log']['study_name']
        #oracle_server_scp = config['oracle_conn']['oracle_server']
        oracle_server_scp = "bardscpi@lctcvd1538.merck.com"

        logfile_path = Path(config['audit_log']['log_path']).joinpath(f"cdl_sdtm_extraction_{audit_log_sq_no}_py.log")
        logging.basicConfig(format='%(asctime)s - %(levelname)s - %(message)s', handlers=[logging.FileHandler(logfile_path)], level=logging.INFO)

        logging.info(f"Starting CDL SDTM Extraction for - {study_name}")
        session = get_oracle_db_session(config)
        logging.info("Oracle Onprem DB session established successfully!!")

        conn = establish_databricks_connection(config, session, audit_log_sq_no, logfile_path, oracle_server_scp)
        logging.info("Databricks Connection is established successfully!!")

        schema_presence = validate_schema_existence(conn, catalog_name, schema_name, session, audit_log_sq_no, logfile_path, oracle_server_scp)
        if not schema_presence:
            logging.error("Study Schema is not available in databricks - Exiting!!!")
            error_message_schema = """<br>
                             <strong>ExtractCDLSDTMDataException:</strong> The Study Schema is not available in CDL databricks. Further execution aborted.<br>
                             <strong>Error Cause:</strong> Study schema not found in CDL databricks.<br>
                             <strong>Next Steps:</strong> Submit a CPI request to report the issue."""
            zip_and_transfer(audit_log_sq_no, logfile_path, oracle_server_scp)
            update_audit_log_table(session, 'FAIL', error_message_schema, audit_log_sq_no)
            return
        logging.info("Study Schema is available in databricks")

        domains_list = fetch_databricks_table_info(conn, catalog_name, schema_name, session, audit_log_sq_no, logfile_path, oracle_server_scp)
        logging.info("Number of domains for the given study in databricks schema")
        logging.info(len(domains_list))

        if not domains_list:
            logging.error("No tables are available in databricks for the given schema - Exiting!!!")
            error_message_table = """<br>
                             <strong>ExtractCDLSDTMDataException:</strong> There are no domains present under the study schema in CDL databricks. Further execution aboretd.<br>
                             <strong>Error Cause:</strong> There are no tables/domains under the given study schema.<br>
                             <strong>Next Steps:</strong> Submit a CPI request to report the issue."""
            zip_and_transfer(audit_log_sq_no, logfile_path, oracle_server_scp)
            update_audit_log_table(session, 'FAIL', error_message_table, audit_log_sq_no)
            return

        # domains_list = ['ae', 'dm', 'cm']
        for domains in domains_list:
            # Query to get the next value from the sequence
            logging.info("Inside Loop - Creating Seqnum")
            sequence_sql = text("SELECT SDTM_AUDIT_DATASET_LOG_SEQ.NEXTVAL FROM DUAL")
            result = session.execute(sequence_sql)
            dataset_log_sq_no = result.fetchone()[0]

            insert_sql = text("""INSERT INTO BARDSCPI.SDTM_AUDIT_DATASET_LOG (AUDIT_LOG_SEQ_NO, AUDIT_DATASET_LOG_SEQ_NO, DATASET_NAME, STATUS_CD, START_TIME)VALUES (:audit_log, :audit_dataset_log, :domain, :status, SYSDATE)""")
            session.execute(insert_sql, {
                    "audit_log": audit_log_sq_no,
                    "audit_dataset_log": dataset_log_sq_no,
                    "domain": domains,
                    "status": 'IN-PROGRESS'
                })

            session.commit()
            logging.info("Domain record is inserted and status was set to InProgress in audit_dataset_log table")

            # Start the background task - for parllel execution
            start_background_task(config, domains, dataset_log_sq_no)



    except Exception as e:
        logging.error(f"Error in extarction of cdl-sdtm dataset {e}")
        sys.exit(1)

    finally:
        # Clean up resources
        if session:
            session.close()
            logging.info("Session closed successfully.")
        if conn:
            conn.close()
            logging.info("Connection closed successfully.")


if __name__ == '__main__':
    main()
